{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c126020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "from src.utils.hf_utils import download_weights\n",
    "from src.utils.vit_config import inizialize_model\n",
    "from src.data.dataset import PatchFromH5Dataset\n",
    "from src.rl.train import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e280d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_STEPS = 100000 \n",
    "LEARNING_RATE = 5e-5 \n",
    "WEIGHT_DECAY = 0.01 \n",
    "DECAY_TYPE = \"cosine\"\n",
    "WARMUP_STEPS = 500\n",
    "IMG_SIZE = 224\n",
    "TRAIN_BATCH_SIZE = 8 \n",
    "VAL_BATCH_SIZE = 8 \n",
    "NUM_CLASSES = 6\n",
    "EVAL_EVERY = 500 \n",
    "GRADIENT_ACCUMULATION_STEPS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ef725",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_WEIGHTS_PATH = \"/equilibrium/datasets/TCGA-histological-data/vit_weights_cache\"\n",
    "weights_path = download_weights(HF_WEIGHTS_PATH)\n",
    "\n",
    "timm_pretrained_state_dict = torch.load(weights_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b54047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inizialize_model(timm_pretrained_state_dict, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PatchFromH5Dataset(\n",
    "    h5_dir='/equilibrium/datasets/TCGA-histological-data/hest_dataset/datasets--MahmoodLab--hest/snapshots/cf37675c2006e6dfcdaa084ddeca863d21a8ddbb/patches',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [dataset.label_to_idx[dataset.sample_to_label[file.replace('.h5','')]]\n",
    "          for (file, _) in dataset.data_index]\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    "# Split stratificato\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "# Crea i Subset\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=16)\n",
    "val_loader = DataLoader(val_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ff9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of classes in train and val sets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_class_distribution(labels, title):\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    plt.bar(unique, counts)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.xticks(unique)\n",
    "    plt.show()\n",
    "plot_class_distribution([labels[i] for i in train_idx], \"Train Set Class Distribution\")\n",
    "plot_class_distribution([labels[i] for i in val_idx], \"Validation Set Class Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=0.9,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b82ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DECAY_TYPE == \"cosine\":\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=WARMUP_STEPS,\n",
    "        num_training_steps=NUM_STEPS\n",
    "    )\n",
    "else: # DECAY_TYPE == \"linear\"\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=WARMUP_STEPS,\n",
    "        num_training_steps=NUM_STEPS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    \"name\": \"vit_training_notebook_run\",\n",
    "    \"output_dir\": \"./output_notebook\",\n",
    "    \"eval_every\": EVAL_EVERY, \n",
    "    \"num_steps\": NUM_STEPS,\n",
    "    \"learning_rate\": LEARNING_RATE, # Passa l'LR se il trainer lo calcola internamente\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"decay_type\": DECAY_TYPE,\n",
    "    \"warmup_steps\": WARMUP_STEPS,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"local_rank\": -1, # Usa -1 per non distribuito in un singolo notebook\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n",
    "    \"fp16\": False, # Abilita o disabilita AMP\n",
    "    \"img_size\": IMG_SIZE, # Necessario per UCB_Count_Score\n",
    "    \"train_batch_size\": TRAIN_BATCH_SIZE, # Necessario per UCB_Count_Score\n",
    "     \"num_classes\": NUM_CLASSES,\n",
    "}\n",
    "\n",
    "args = TrainingArguments(**training_params)\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=val_loader,\n",
    "    loss_function=loss_function,\n",
    "    optimizer=optimizer, \n",
    "    scheduler=scheduler \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b158ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
