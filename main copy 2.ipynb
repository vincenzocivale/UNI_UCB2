{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c126020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.data.dataset import PatchFromH5Dataset, stratified_split, plot_class_distributions\n",
    "from src.rl.train import ViTUCBTrainer\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from src.rl.modelling import ViT_UCB_Pruning\n",
    "import evaluate\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3ec15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_PROJECT\"] = \"ViT-Pruning-Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e280d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "PRUNING_RATIO = 0.3\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea90e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PatchFromH5Dataset(\n",
    "    h5_dir='/equilibrium/datasets/TCGA-histological-data/hest/patches/patches/',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d111973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfdf2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_796240/3282357617.py:13: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Crea un DataFrame con indici e label\n",
    "df = pd.DataFrame({\n",
    "    \"index\": np.arange(len(labels)),\n",
    "    \"label\": labels\n",
    "})\n",
    "\n",
    "# Trova il numero di elementi della classe minoritaria\n",
    "min_count = df[\"label\"].value_counts().min()\n",
    "\n",
    "# Per ogni classe, seleziona min_count elementi a caso\n",
    "undersampled_df = (\n",
    "    df.groupby(\"label\", group_keys=False)\n",
    "      .apply(lambda x: x.sample(n=min_count, random_state=42)).reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Mischia gli indici\n",
    "undersampled_indices = undersampled_df[\"index\"].sample(frac=1, random_state=42).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c3ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled_labels = [labels[i] for i in undersampled_indices]\n",
    "\n",
    "trainval_idx, test_idx = train_test_split(\n",
    "    undersampled_indices,\n",
    "    test_size=0.3,\n",
    "    stratify=undersampled_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ottieni i label corrispondenti per il secondo split\n",
    "trainval_labels = [labels[i] for i in trainval_idx]\n",
    "\n",
    "# Split: train vs val\n",
    "train_idx, val_idx = train_test_split(\n",
    "    trainval_idx,\n",
    "    test_size=0.3,\n",
    "    stratify=trainval_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Crea i subset\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset   = Subset(dataset, val_idx)\n",
    "test_dataset  = Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa62405",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd2b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"vit-ucb-pruning-{PRUNING_RATIO}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6825491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 27\n",
      "Loading source model 'hf-hub:MahmoodLab/uni'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/03/2025 12:07:48 - INFO - timm.models._builder - Loading pretrained weights from Hugging Face hub (MahmoodLab/uni)\n"
     ]
    }
   ],
   "source": [
    "labels_num = len(np.unique(dataset.labels))\n",
    "\n",
    "print(f\"Number of classes: {labels_num}\")\n",
    "model = ViT_UCB_Pruning(model_name=\"hf-hub:MahmoodLab/uni\", \n",
    "    pretrained=True, \n",
    "    n_classes=labels_num, \n",
    "    keep_ratio=PRUNING_RATIO,        \n",
    "    exclude_cls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca083829",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    # --- Gestione dei salvataggi e output ---\n",
    "    output_dir=f\"/equilibrium/datasets/TCGA-histological-data/ViT-UCB-Pruning-checkpoints/Ratio-{PRUNING_RATIO}\",  # Directory temporanea, non userÃ  molto spazio\n",
    "    report_to=\"wandb\",                   \n",
    "    push_to_hub=True,                    \n",
    "    hub_model_id=f\"Yuto2007/ViT-UCB-Pruning\",\n",
    "    run_name=run_name, \n",
    "\n",
    "    # --- Pianificazione del training ---\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    \n",
    "    # --- Learning Rate Scheduler ---\n",
    "    learning_rate=1e-1,\n",
    "    warmup_steps=500,                     \n",
    "    weight_decay=0.01,\n",
    "\n",
    "    # --- Valutazione e Best Model ---\n",
    "    eval_strategy=\"epoch\",          \n",
    "    save_strategy=\"epoch\",               \n",
    "    load_best_model_at_end=True,         \n",
    "    metric_for_best_model=\"eval_loss\",    \n",
    "    greater_is_better=False,             \n",
    "\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=1,    \n",
    "\n",
    "    fp16=False             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1a9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=7,\n",
    "    early_stopping_threshold=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12bdb239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vit_ucb_collate_fn(batch):\n",
    "    pixel_values = []\n",
    "    labels = []\n",
    "\n",
    "    for item in batch:\n",
    "        patch = item['pixel_values']\n",
    "        label = item['labels']\n",
    "\n",
    "        # Assicuriamoci che la patch abbia sempre 3 dimensioni (C,H,W)\n",
    "        if patch.ndim == 2:  # scala di grigi\n",
    "            patch = patch.unsqueeze(0)\n",
    "        elif patch.ndim == 3 and patch.shape[2] == 3:  # HWC -> CHW\n",
    "            patch = patch.permute(2, 0, 1)\n",
    "\n",
    "        pixel_values.append(patch)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Stack sicuro\n",
    "    pixel_values = torch.stack(pixel_values)  # (B,C,H,W)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768d1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ViTUCBTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,           \n",
    "    compute_metrics=compute_metrics,      \n",
    "    callbacks=[early_stopping_callback],\n",
    "    data_collator=vit_ucb_collate_fn  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b158ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Inizio dell'addestramento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvincenzo-civale\u001b[0m (\u001b[33mvincenzo-civale-universi-degli-studi-di-firenze\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vcivale/UNI_UCB2/wandb/run-20250903_120753-8gjhdqqt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/ViT-Pruning-Project/runs/8gjhdqqt' target=\"_blank\">vit-ucb-pruning-0.3</a></strong> to <a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/ViT-Pruning-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/ViT-Pruning-Project' target=\"_blank\">https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/ViT-Pruning-Project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/ViT-Pruning-Project/runs/8gjhdqqt' target=\"_blank\">https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/ViT-Pruning-Project/runs/8gjhdqqt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 97, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/src/rl/modelling.py\", line 183, in forward\n    x, score_delta = block(x, counter=counter, ucb_enabled=ucb_enabled, ucb_count_score=self.ucb_count_scores[i])\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/src/rl/modelling.py\", line 147, in forward\n    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 4.50 MiB is free. Process 806708 has 8.99 GiB memory in use. Including non-PyTorch memory, this process has 1.75 GiB memory in use. Of the allocated memory 1.47 GiB is allocated by PyTorch, and 35.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸš€ Inizio dell\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddestramento...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UNI_UCB2/.venv/lib/python3.10/site-packages/transformers/trainer.py:2197\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2195\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 2197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2198\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2204\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/UNI_UCB2/.venv/lib/python3.10/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/UNI_UCB2/.venv/lib/python3.10/site-packages/transformers/trainer.py:3749\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3746\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3749\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3751\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3753\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3754\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3755\u001b[0m ):\n",
      "File \u001b[0;32m~/UNI_UCB2/src/rl/train.py:410\u001b[0m, in \u001b[0;36mViTUCBTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    405\u001b[0m is_training \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# Chiamiamo il forward del modello con gli argomenti custom\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Durante il training, ucb Ã¨ abilitato e il contatore viene usato\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Durante la valutazione (model.eval()), potresti voler disabilitare ucb\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcounter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step_counter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mucb_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_training\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Abilita UCB solo in training\u001b[39;49;00m\n\u001b[1;32m    415\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Se il modello Ã¨ in training, incrementiamo il nostro contatore\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_training:\n",
      "File \u001b[0;32m~/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:194\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    193\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 194\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:213\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparallel_apply\u001b[39m(\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[1;32m    212\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Any]:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:127\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    125\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 127\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/_utils.py:750\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 97, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/src/rl/modelling.py\", line 183, in forward\n    x, score_delta = block(x, counter=counter, ucb_enabled=ucb_enabled, ucb_count_score=self.ucb_count_scores[i])\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/vcivale/UNI_UCB2/src/rl/modelling.py\", line 147, in forward\n    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 4.50 MiB is free. Process 806708 has 8.99 GiB memory in use. Including non-PyTorch memory, this process has 1.75 GiB memory in use. Of the allocated memory 1.47 GiB is allocated by PyTorch, and 35.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ Inizio dell'addestramento...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸš€ Valutazione finale sul test set con il modello migliore...\")\n",
    "test_results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Risultati del Test Set:\")\n",
    "print(test_results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.log({\"final_test_metrics\": test_results.metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162afae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "print(\"\\nâœ… Addestramento e valutazione completati.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
